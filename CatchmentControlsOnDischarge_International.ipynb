{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPARjydjy/TMIKCpExAV3NU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simreaney/CAMELS-GB-2-HBV-Light/blob/main/CatchmentControlsOnDischarge_International.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting Catchment Controls on River Discharge - International Edition\n",
        "## Managing River Catchments, Durham University.  \n",
        "Sim M. Reaney 20234  \n",
        "In this notebook, you can look at the relationships between the catchment characteristics and the discharge measured from the gauging station. You are going to build a statistical model to predict the runoff ratio based on the catchment descriptors.  You are going to do this analysis for the GB dataset. There are also the USA and Australian datasets available to see if the same relationships hold for a different geographical region.\n",
        "  \n",
        "## What you need to do:\n",
        "* **Mapping patterns** - here you can get a visual sense of the spatial patterns of the controls on runoff for the country you are looking at. this section is for context.\n",
        "* **Single linear regression** - here you are going to look at each control on the runoff ratio and make a short list of the ones that have the greatest predictive power.\n",
        "* **Multiple linear regression** - here you will take you short list from the previous step and use it to make a selection of the top three controls whicj when combined, gives the best prediction of the runoff ratio.\n",
        "* **Multiple non-linear regression** - here you will extend your analysis from the previous step and use non-linear regression to further improve the prediction of the runoff ratio.\n",
        "\n",
        "The notebook is made up of a set of blocks of Python code, options on the right and the results shown in the graphs and maps. To run a block of code, click the play button in the top right of the code. This button is the triangle in the circle. You will not need to edit any of the code to make this analysis work."
      ],
      "metadata": {
        "id": "LX5bcJHV7fui"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mapping patterns\n",
        "\n",
        "The relationships between the catchment characteristics and the runoff percentage can be considered in a spatial context. Take a bit of time to familiarise yourself with the data and its spatial structure.  \n",
        "  \n",
        "In the tool below, you can quickly plot the spatial pattern of the different controls. You can select different colour ramps to show the different controls and you can vary the point size.\n",
        "\n",
        "The catchment descriptors in this workbook are a sub-set from the [CAMELS-GB](https://essd.copernicus.org/articles/12/2459/2020/) dataset (Coxon et al. 2020), the [CAMELS](https://gdex.ucar.edu/dataset/camels.html) dataset (Newman et al. 2014) for the USA,  the [CAMELS-AUS](https://essd.copernicus.org/articles/13/3847/2021/) dataset for Australia (Fowler et al. 2021) and from [CAMELS-Brazil](https://essd.copernicus.org/articles/12/2075/2020/) (Chagas et al 2020). You can investigate the role and effect of the following descriptors:\n",
        "* *area_gages2* - catchment area, km<sup>2</sup>\n",
        "* *elev_mean* - gauge elevation, masl\n",
        "* *slope_mean* - catchment mean drainage path slope, m km<sup>−1</sup>\n",
        "* *soil_conductivity* - saturated hydraulic conductivity, cm hr<sup>-1</sup>\n",
        "* *soil_depth_pelletier* - depth to bedrock (maximum 50 m), m\n",
        "* *soil_porosity* - volumetric porosity (saturated volumetric water content, %). Only for USA and GB.\n",
        "* *frac_forest* - percentage cover of deciduous woodland, %\n",
        "* *p_mean* - mean daily precipitation, mm day<sup>-1</sup>\n",
        "* *frac_snow* - fraction of the precipitation delivered as snow, %\n",
        "* *aridity* - aridity, calculated as the ratio of mean daily potential evapotranspiration to mean daily precipitation, index\n",
        "\n",
        "In this workshop, you are going to focus on the runoff ratio (runoff_ratio). This is the total discharge (m<sup>3</sup>) divided by the total rainfall (m<sup>3</sup>), 0 - 1 (1 = 100%)\n",
        "\n",
        "First, we need to install a new library called [Contextily](https://contextily.readthedocs.io/) that does the background contexty mapping for the dataset. Once the step below has been completed, then you can create the maps.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "T72EgGJ7JsHI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install and import the libraries - run this block once.\n",
        "import geopandas\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from bokeh.plotting import figure, output_file, show, output_notebook\n",
        "\n",
        "from google.colab import data_table\n",
        "%load_ext google.colab.data_table\n",
        "\n",
        "print (\"Installing contextily...\")\n",
        "!pip install contextily  --quiet\n",
        "print (\"done\")\n",
        "import contextily as cx\n",
        "\n",
        "output_notebook()\n",
        "print(\"Now, you can use the mapping tool below.\")\n"
      ],
      "metadata": {
        "id": "HamvVWKlKm02",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Plotting discharge controls on a map\n",
        "control3 = \"soil_conductivity\" #@param [\"runoff_ratio\", \"q_mean\", \"area_gages2\",\"elev_mean\",'slope_mean','soil_conductivity','soil_depth_pelletier','soil_porosity','frac_forest', 'frac_snow','p_mean', 'aridity']\n",
        "pointSize = 69 #@param {type:\"slider\", min:5, max:300, step:1}\n",
        "colourRamp = \"viridis\" #@param [\"autumn\", \"viridis\",\"plasma\",\"inferno\",\"magma\"]\n",
        "location =\"USA\" #@param [\"GB\",\"USA\",\"AUS\",\"Brazil\"]\n",
        "\n",
        "\n",
        "#Read the CAMELS-GB dataset from the web\n",
        "df = pd.read_csv('https://github.com/simreaney/simreaney.github.io/raw/master/MRC/workshop/CAMELS-' + location + '.csv', na_values=['?'])\n",
        "flow = \"runoff_ratio\"\n",
        "\n",
        "# #plotting\n",
        "gdf = geopandas.GeoDataFrame(df, geometry=geopandas.points_from_xy(df.gauge_lon, df.gauge_lat), crs=\"EPSG:4326\")\n",
        "\n",
        "if location==\"GB\":\n",
        "  gdf_bng = gdf.to_crs(\"EPSG:27700\")\n",
        "\n",
        "  fig, axs = plt.subplots(1, 1, figsize=(10, 10))\n",
        "\n",
        "  # First map\n",
        "  axs.set_title(control3)\n",
        "  gdf_bng.plot(ax=axs, markersize=pointSize, alpha=0.6, column=df[control3], cmap=colourRamp, legend=True)\n",
        "  cx.add_basemap(axs, crs=gdf_bng.crs, source=cx.providers.OpenStreetMap.Mapnik)\n",
        "\n",
        "elif location==\"USA\":\n",
        "\n",
        "  fig, axs = plt.subplots(1, 1, figsize=(10, 5))\n",
        "\n",
        "  # First map\n",
        "  axs.set_title(control3)\n",
        "  gdf.plot(ax=axs, markersize=pointSize, alpha=0.6, column=df[control3], cmap=colourRamp, legend=True)\n",
        "  cx.add_basemap(axs, crs=gdf.crs, source=cx.providers.OpenStreetMap.Mapnik)\n",
        "\n",
        "elif location==\"AUS\":\n",
        "\n",
        "  fig, axs = plt.subplots(1, 1, figsize=(10, 5))\n",
        "\n",
        "  # First map\n",
        "  axs.set_title(control3)\n",
        "  gdf.plot(ax=axs, markersize=pointSize, alpha=0.6, column=df[control3], cmap=colourRamp, legend=True)\n",
        "  cx.add_basemap(axs, crs=gdf.crs, source=cx.providers.OpenStreetMap.Mapnik)\n",
        "\n",
        "elif location==\"Brazil\":\n",
        "\n",
        "  fig, axs = plt.subplots(1, 1, figsize=(10, 5))\n",
        "\n",
        "  # First map\n",
        "  axs.set_title(control3)\n",
        "  gdf.plot(ax=axs, markersize=pointSize, alpha=0.6, column=df[control3], cmap=colourRamp, legend=True)\n",
        "  cx.add_basemap(axs, crs=gdf.crs, source=cx.providers.OpenStreetMap.Mapnik)\n"
      ],
      "metadata": {
        "id": "pWLqg7kMJvVU",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Single Linear Regression\n",
        "In this section, you are going to look at the statistical power of the individual catchment descriptors using linear regression. For each of the controls, run the code and note down the R<sup>2</sup> value. You are then going to use this list to inform the multiple regression in the next step."
      ],
      "metadata": {
        "id": "5w-7Blm9CTDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "control4 = \"aridity\" #@param [\"area_gages2\",\"elev_mean\",'slope_mean','soil_conductivity','soil_depth_pelletier','soil_porosity','frac_forest', 'lai_max', 'frac_snow','p_mean', 'aridity']\n",
        "\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from bokeh.plotting import figure, show\n",
        "from bokeh.layouts import gridplot\n",
        "import numpy as np\n",
        "\n",
        "reg = linear_model.LinearRegression()\n",
        "reg.fit(df[[control4]], df['runoff_ratio'])\n",
        "runoffPred = reg.predict(df[[control4]])\n",
        "\n",
        "# The coefficients\n",
        "print(\"Coefficients: \", reg.coef_)\n",
        "print(\"Intercept: \", reg.intercept_)\n",
        "# The mean squared error\n",
        "# print(\"Mean squared error: %.2f\" % mean_squared_error(df['runoff_ratio'], runoffPred))\n",
        "# The coefficient of determination: 1 is perfect prediction\n",
        "print(\"Coefficient of determination (R²): %.2f\" % r2_score(df['runoff_ratio'], runoffPred))\n",
        "\n",
        "# Plot outputs\n",
        "p1 = figure(y_axis_label='observed runoff ratio', x_axis_label=control4, width=400, height=400)\n",
        "p1.scatter(df[control4], df['runoff_ratio'], size=2, color='purple', alpha=0.7, legend_label='Individual catchments')\n",
        "# # Create a line of best fit\n",
        "x_range = np.linspace(min(df[control4]), max(df[control4]), 100)\n",
        "y_range = reg.predict(x_range.reshape(-1, 1))\n",
        "p1.line(x_range, y_range, line_width=2, color='blue', legend_label='Line of Best Fit')\n",
        "\n",
        "# Plot outputs\n",
        "p = figure(y_axis_label='predicted runoff ratio', x_axis_label='observed runoff ratio', width=400, height=400)\n",
        "p.scatter(df['runoff_ratio'], runoffPred, size=2, color='orange', alpha=0.7, legend_label='Individual catchments')\n",
        "\n",
        "# Create and show a grid of the two plots\n",
        "grid = gridplot([[p1, p]])\n",
        "show(grid)\n"
      ],
      "metadata": {
        "id": "JFfFTy35CXlo",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multiple Linear Regression\n",
        "As you will have seen, there is not one individual varable that effectively predicts the runoff ratio. Therefore, in this next step, you are going to do a multiple linear regression analysis using the top set of individual factors from the previous step. It is likely that the top performing model will not be made up simply of the top three R<sup>2</sup> controls from the previous step. You need to consider the information content in each and what it is telling you about the catchment's response to rainfall."
      ],
      "metadata": {
        "id": "PBmrmcVsK2sG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "control_1 = \"aridity\" #@param [\"area_gages2\",\"elev_mean\",'slope_mean','soil_conductivity','soil_depth_pelletier','soil_porosity','frac_forest', 'lai_max', 'frac_snow','p_mean', 'aridity']\n",
        "control_2 = \"slope_mean\" #@param [\"area_gages2\",\"elev_mean\",'slope_mean','soil_conductivity','soil_depth_pelletier','soil_porosity','frac_forest', 'lai_max', 'frac_snow','p_mean', 'aridity']\n",
        "control_3 = \"elev_mean\" #@param [\"area_gages2\",\"elev_mean\",'slope_mean','soil_conductivity','soil_depth_pelletier','soil_porosity','frac_forest', 'lai_max', 'frac_snow','p_mean', 'aridity']\n",
        "\n",
        "\n",
        "regMulti = linear_model.LinearRegression()\n",
        "regMulti.fit(df[[control_1, control_2, control_3]], df['runoff_ratio'])\n",
        "runoffPred = regMulti.predict(df[[control_1, control_2, control_3]])\n",
        "\n",
        "# The coefficients\n",
        "print(\"Coefficients: \\n\", regMulti.coef_)\n",
        "# The mean squared error\n",
        "# print(\"Mean squared error: %.2f\" % mean_squared_error(df['runoff_ratio'], runoffPred))\n",
        "# The coefficient of determination: 1 is perfect prediction\n",
        "print(\"Coefficient of determination (R²): %.2f\" % r2_score(df['runoff_ratio'], runoffPred))\n",
        "\n",
        "# Plot outputs\n",
        "p = figure(y_axis_label='predicted runoff ratio', x_axis_label='observed runoff ratio', width=600, height=600)\n",
        "p.scatter(df['runoff_ratio'], runoffPred, size=2, color='purple', legend_label='Individual catchments')\n",
        "\n",
        "# Add a line of best fit 1:1\n",
        "x_range = (min(df['runoff_ratio']), max(df['runoff_ratio']))\n",
        "y_range = (min(runoffPred), max(runoffPred))\n",
        "p.line(x_range, x_range, line_width=2, line_color=\"blue\", alpha=0.7, legend_label='Line of Best Fit')\n",
        "\n",
        "show(p)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "KHmh47mmK15j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multiple Non-linear regression\n",
        "You will have seen that many of the relationships between the runoff ratio and the catchment descriptors are non-linear. Therefore, we can explore the data with a regression model that can capture these non-linear relationships. We are going to use a polynomial equation that has the form:  \n",
        "\n",
        "$$y = ß_0 + ß_1x + ß_2x^2 + … + ß_nx^n$$\n",
        "\n",
        "Where:\n",
        "* $y$ is the variable we want to predict,\n",
        "* $x$ is the input control, such as aridity\n",
        "* $ß_0$ is the $y$ intercept,\n",
        "* The other $ß$s are the other coefficients\n",
        "* $n$ is the degree of the polynomial (the higher n is, the more complex curved lines are created).\n",
        "\n",
        "You can follow the same steps as for multiple linear regression and work out the three controls that are best able to fit the observed patterns of the runoff ratio. There is a control for adjusting the complexity of the statistical model ('degree'). Ideally, a simpler model is preferred:\n",
        "> \"a model should be as simple as possible but no simpler\", [Occam's razor](https://en.wikipedia.org/wiki/Occam%27s_razor)).\n",
        "\n",
        "Therefore, try to balance the complexity of the model with the predictive power.\n",
        "\n"
      ],
      "metadata": {
        "id": "aBpcsknIUCm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "control_1 = \"elev_mean\" #@param [\"area_gages2\",\"elev_mean\",'slope_mean','soil_conductivity','soil_depth_pelletier','soil_porosity','frac_forest', 'frac_snow','p_mean', 'aridity']\n",
        "control_2 = \"slope_mean\" #@param [\"area_gages2\",\"elev_mean\",'slope_mean','soil_conductivity','soil_depth_pelletier','soil_porosity','frac_forest', 'frac_snow','p_mean', 'aridity']\n",
        "control_3 = \"soil_depth_pelletier\" #@param [\"area_gages2\",\"elev_mean\",'slope_mean','soil_conductivity','soil_depth_pelletier','soil_porosity','frac_forest', 'frac_snow','p_mean', 'aridity']\n",
        "degree = 2 #@param {type:\"slider\", min:1, max:6, step:1}\n",
        "\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "poly_reg_model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
        "poly_reg_model.fit(df[[control_1, control_2, control_3]], df['runoff_ratio'])\n",
        "runoffPred = poly_reg_model.predict(df[[control_1, control_2, control_3]])\n",
        "\n",
        "# The coefficients\n",
        "# print(\"Coefficients: \\n\", poly_reg_model.named_steps['linearregression'].coef_)\n",
        "# The coefficient of determination: 1 is perfect prediction\n",
        "print(\"Coefficient of determination (R²): %.2f\" % r2_score(df['runoff_ratio'], runoffPred))\n",
        "\n",
        "# Plot outputs\n",
        "p = figure(y_axis_label='predicted runoff ratio', x_axis_label='observed runoff ratio', width=600, height=600)\n",
        "p.scatter(df['runoff_ratio'], runoffPred, size=2, color='purple', legend_label='Individual catchments')\n",
        "\n",
        "# Add a line of best fit 1:1\n",
        "x_range = (min(df['runoff_ratio']), max(df['runoff_ratio']))\n",
        "y_range = (min(runoffPred), max(runoffPred))\n",
        "p.line(x_range, x_range, line_width=2, line_color=\"blue\", alpha=0.7, legend_label='Line of Best Fit')\n",
        "\n",
        "show(p)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "f1wLoH05PhSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Show me the data!\n",
        "If you want to see the data set that sits behind this analysis, run the block of code below"
      ],
      "metadata": {
        "id": "F15xLuTxYQou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "df\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "R0yASzBfXLNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References:  \n",
        "Chagas, V. B. P., Chaffe, P. L. B., Addor, N., Fan, F. M., Fleischmann, A. S., Paiva, R. C. D., and Siqueira, V. A.: CAMELS-BR: hydrometeorological time series and landscape attributes for 897 catchments in Brazil, Earth Syst. Sci. Data, 12, 2075–2096, https://doi.org/10.5194/essd-12-2075-2020, 2020.\n",
        "\n",
        "Coxon, G., Addor, N., Bloomfield, J. P., Freer, J., Fry, M., Hannaford, J., Howden, N. J. K., Lane, R., Lewis, M., Robinson, E. L., Wagener, T., and Woods, R. 2020: CAMELS-GB: hydrometeorological time series and landscape attributes for 671 catchments in Great Britain, Earth Syst. Sci. Data, 12, 2459–2483, https://doi.org/10.5194/essd-12-2459-2020\n",
        "\n",
        "Fowler, K. J. A., Acharya, S. C., Addor, N., Chou, C., and Peel, M. C.: CAMELS-AUS: hydrometeorological time series and landscape attributes for 222 catchments in Australia, Earth Syst. Sci. Data, 13, 3847–3867, https://doi.org/10.5194/essd-13-3847-2021, 2021.\n",
        "\n",
        "Newman A.; Sampson K., Clark M. P., Bock A., Viger R. J. and Blodgett D., 2014. A large-sample watershed-scale hydrometeorological dataset for the contiguous USA. Boulder, CO: UCAR/NCAR. https://dx.doi.org/10.5065/D6MW2F4D\n",
        "\n",
        "---\n",
        "\n",
        "Built with [Pandas](https://pandas.pydata.org/), [Numpy](https://numpy.org/), [GeoPandas](https://geopandas.org/en/stable/), [Bokeh](http://bokeh.org/), [Contextily](https://contextily.readthedocs.io/) and [scikit-learn](https://scikit-learn.org/stable/).\n",
        "\n",
        "---\n",
        "Sim M. Reaney, Durham University.  \n",
        "[simreaney.github.io](https://simreaney.github.io)  \n",
        "[@simreaney](https://twitter.com/simreaney)"
      ],
      "metadata": {
        "id": "i7Cw8Y7ZlO3h"
      }
    }
  ]
}